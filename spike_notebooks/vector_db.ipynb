{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document, component\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.generators.openai_utils import _convert_message_to_openai_format\n",
    "from haystack.dataclasses import ChatMessage, StreamingChunk\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "# from haystack_integrations.components.embedders.cohere import CohereDocumentEmbedder, CohereTextEmbedder\n",
    "from haystack.components.embedders import OpenAITextEmbedder, OpenAIDocumentEmbedder\n",
    "from haystack_integrations.document_stores.chroma import ChromaDocumentStore\n",
    "\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI, Stream\n",
    "from openai.types.chat import ChatCompletion, ChatCompletionChunk\n",
    "from typing import List, Any, Dict, Optional, Callable, Union\n",
    "from pydantic import BaseModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "document_store = ChromaDocumentStore(persist_path=\"got_chroma_db\")\n",
    "\n",
    "dataset = load_dataset(\"Tuana/game-of-thrones\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]\n",
    "\n",
    "doc_embedder = OpenAIDocumentEmbedder(model=\"text-embedding-3-small\")\n",
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.retrievers.chroma import ChromaEmbeddingRetriever\n",
    "\n",
    "# Initialize components\n",
    "# retriever = InMemoryEmbeddingRetriever(document_store=document_store, top_k=3)  # Limit to top 3 results\n",
    "document_store = ChromaDocumentStore(persist_path=\"got_chroma_db\")\n",
    "retriever = ChromaEmbeddingRetriever(document_store=document_store, top_k=3)\n",
    "text_embedder = OpenAITextEmbedder(model=\"text-embedding-3-small\")\n",
    "generator = OpenAIGenerator()\n",
    "\n",
    "# Build prompt template\n",
    "template = \"\"\"Answer the question based on the provided context and chat history. If you cannot find the answer in the context, say so.\n",
    "\n",
    "Previous conversation:\n",
    "{% for message in chat_history %}\n",
    "{% if message.role == 'user' %}User: {{ message.content }}{% endif %}\n",
    "{% if message.role == 'assistant' %}Assistant: {{ message.content }}{% endif %}\n",
    "{% endfor %}\n",
    "\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "{{ doc.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=template)\n",
    "\n",
    "class ChatSession:\n",
    "    def __init__(self):\n",
    "        self.chat_history = []\n",
    "        self.context_history = []\n",
    "        \n",
    "    def chat(self, question: str):\n",
    "        # Embed question and retrieve relevant docs\n",
    "        embedded_query = text_embedder.run(question)\n",
    "        retrieved_docs = retriever.run(embedded_query[\"embedding\"])\n",
    "        \n",
    "        # Store context\n",
    "        self.context_history.extend(retrieved_docs[\"documents\"])\n",
    "        \n",
    "        # Build prompt with retrieved context and chat history\n",
    "        prompt_params = {\n",
    "            # \"documents\": retrieved_docs[\"documents\"], \n",
    "            \"documents\": self.context_history,\n",
    "            \"question\": question,\n",
    "            \"chat_history\": self.chat_history\n",
    "        }\n",
    "        prompt = prompt_builder.run(**prompt_params)\n",
    "        \n",
    "        # Generate answer\n",
    "        response = generator.run(prompt[\"prompt\"])\n",
    "        answer = response[\"replies\"][0]\n",
    "        \n",
    "        # Update chat history\n",
    "        self.chat_history.append(ChatMessage.from_user(question))\n",
    "        self.chat_history.append(ChatMessage.from_assistant(answer))\n",
    "        \n",
    "        return f\"{answer}\\n\\nSources: {', '.join(list(set([i.meta[\"name\"] for i in session.context_history])))}\" #output the document names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session = ChatSession()\n",
    "\n",
    "while True:\n",
    "    message = input(\"Ask a question about Game of Thrones (type 'exit' to quit): \")\n",
    "    if message.lower() == 'exit':\n",
    "        print(\"Exiting the chat session.\")\n",
    "        break\n",
    "    response = session.chat(message)\n",
    "    print(f\"Assistant: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30_List_of_A_Song_of_Ice_and_Fire_characters.txt',\n",
       " '43_Arya_Stark.txt',\n",
       " '371_Cersei_Lannister.txt']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio chat interface\n",
    "import gradio as gr\n",
    "\n",
    "session = ChatSession()\n",
    "\n",
    "def chat_response(message, history):\n",
    "    return session.chat(message)\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_response,\n",
    "    title=\"Game of Thrones Chat\", \n",
    "    description=\"Ask questions about Game of Thrones\",\n",
    ")\n",
    "\n",
    "demo.launch(show_api=False, share=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write a 3 paragraph summary of aria starks personality and drivers\n",
    "\n",
    "how has her sister influenced her?\n",
    "\n",
    "who influenced her more (both positive and negative) sansa or the hound?\n",
    "\n",
    "a choice between the two"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
