{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to run `make install-spacy` to install the spaCy model\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "\n",
    "# Get the project root directory and data path\n",
    "project_root = Path.cwd().parent  # Go up one level from notebooks directory\n",
    "data_dir = project_root / \"data\" / \"actions\"\n",
    "\n",
    "# Get the first text file\n",
    "text_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]\n",
    "first_file = os.path.join(data_dir, text_files[0])\n",
    "\n",
    "# Read the contents\n",
    "with open(first_file, 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "#Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Sustainable Farming Incentive (SFI WORK_OF_ART\n",
      "2024 DATE\n",
      "SFI ORG\n",
      "5 years DATE\n",
      "215 MONEY\n",
      "the year DATE\n",
      "each year DATE\n",
      "each year DATE\n",
      "5-year DATE\n",
      "summer 2024 DATE\n",
      "winter DATE\n",
      "summer DATE\n",
      "section 6 ‘Eligible LAW\n",
      "National Insurance ORG\n"
     ]
    }
   ],
   "source": [
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sustainable B-MISC\n",
      "Farm I-MISC\n",
      "##ing I-MISC\n",
      "Inc I-MISC\n",
      "##ent I-MISC\n",
      "##ive I-MISC\n",
      "SF B-MISC\n",
      "SF B-MISC\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "# sentence = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "ner_results = nlp(text)\n",
    "\n",
    "for entity in ner_results:\n",
    "    print(entity['word'], entity['entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-MISC',\n",
       "  'score': np.float32(0.6266002),\n",
       "  'index': 7,\n",
       "  'word': 'Sustainable',\n",
       "  'start': 25,\n",
       "  'end': 36},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': np.float32(0.64785767),\n",
       "  'index': 8,\n",
       "  'word': 'Farm',\n",
       "  'start': 37,\n",
       "  'end': 41},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': np.float32(0.56808525),\n",
       "  'index': 9,\n",
       "  'word': '##ing',\n",
       "  'start': 41,\n",
       "  'end': 44},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': np.float32(0.7891627),\n",
       "  'index': 10,\n",
       "  'word': 'Inc',\n",
       "  'start': 45,\n",
       "  'end': 48},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': np.float32(0.79436713),\n",
       "  'index': 11,\n",
       "  'word': '##ent',\n",
       "  'start': 48,\n",
       "  'end': 51},\n",
       " {'entity': 'I-MISC',\n",
       "  'score': np.float32(0.80697817),\n",
       "  'index': 12,\n",
       "  'word': '##ive',\n",
       "  'start': 51,\n",
       "  'end': 54},\n",
       " {'entity': 'B-MISC',\n",
       "  'score': np.float32(0.8021642),\n",
       "  'index': 14,\n",
       "  'word': 'SF',\n",
       "  'start': 56,\n",
       "  'end': 58},\n",
       " {'entity': 'B-MISC',\n",
       "  'score': np.float32(0.76270396),\n",
       "  'index': 29,\n",
       "  'word': 'SF',\n",
       "  'start': 112,\n",
       "  'end': 114}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/adamfletcher/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  This/DT\n",
      "  is/VBZ\n",
      "  an/DT\n",
      "  action/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Sustainable/JJ Farming/NNP Incentive/NNP)\n",
      "  (/(\n",
      "  (ORGANIZATION SFI/NNP)\n",
      "  )/)\n",
      "  scheme/NN\n",
      "  :/:\n",
      "  expanded/VBN\n",
      "  offer/NN\n",
      "  for/IN\n",
      "  2024/CD\n",
      "  ./.\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  read/VB\n",
      "  the/DT\n",
      "  (ORGANIZATION SFI/NNP)\n",
      "  scheme/NN\n",
      "  information/NN\n",
      "  to/TO\n",
      "  understand/VB\n",
      "  the/DT\n",
      "  scheme/NN\n",
      "  rules/NNS\n",
      "  and/CC\n",
      "  how/WRB\n",
      "  to/TO\n",
      "  apply/VB\n",
      "  ./.\n",
      "  5/CD\n",
      "  years/NNS\n",
      "  £215/JJ\n",
      "  per/IN\n",
      "  hectare/NN\n",
      "  (/(\n",
      "  ha/NN\n",
      "  )/)\n",
      "  per/IN\n",
      "  year/NN\n",
      "  This/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  aim/NN\n",
      "  is/VBZ\n",
      "  that/IN\n",
      "  there/EX\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  a/DT\n",
      "  well-managed/JJ\n",
      "  ,/,\n",
      "  intact/JJ\n",
      "  grass/NN\n",
      "  sward/NN\n",
      "  growing/VBG\n",
      "  over/IN\n",
      "  the/DT\n",
      "  historic/JJ\n",
      "  or/CC\n",
      "  archaeological/JJ\n",
      "  feature/NN\n",
      "  throughout/IN\n",
      "  the/DT\n",
      "  year/NN\n",
      "  ,/,\n",
      "  with/IN\n",
      "  minimal/JJ\n",
      "  scrub/NN\n",
      "  cover/NN\n",
      "  and/CC\n",
      "  bare/JJ\n",
      "  ground/NN\n",
      "  ./.\n",
      "  The/DT\n",
      "  purpose/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  is/VBZ\n",
      "  to/TO\n",
      "  :/:\n",
      "  You/PRP\n",
      "  can/MD\n",
      "  do/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  on/IN\n",
      "  land/NN\n",
      "  located/VBN\n",
      "  above/IN\n",
      "  and/CC\n",
      "  below/IN\n",
      "  the/DT\n",
      "  moorland/NN\n",
      "  line/NN\n",
      "  that/IN\n",
      "  ’/JJ\n",
      "  s/NN\n",
      "  :/:\n",
      "  Total/NN\n",
      "  or/CC\n",
      "  part/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  available/JJ\n",
      "  area/NN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  land/NN\n",
      "  parcel/NN\n",
      "  ./.\n",
      "  This/DT\n",
      "  action/NN\n",
      "  is/VBZ\n",
      "  static/JJ\n",
      "  ./.\n",
      "  This/DT\n",
      "  means/VBZ\n",
      "  you/PRP\n",
      "  must/MD\n",
      "  do/VB\n",
      "  it/PRP\n",
      "  at/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  location/NN\n",
      "  each/DT\n",
      "  year/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  duration/NN\n",
      "  ./.\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  manage/VB\n",
      "  the/DT\n",
      "  area/NN\n",
      "  containing/VBG\n",
      "  the/DT\n",
      "  historic/NN\n",
      "  or/CC\n",
      "  archaeological/JJ\n",
      "  feature/NN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  way/NN\n",
      "  that/WDT\n",
      "  can/MD\n",
      "  reasonably/RB\n",
      "  be/VB\n",
      "  expected/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  aim/NN\n",
      "  ./.\n",
      "  This/DT\n",
      "  includes/VBZ\n",
      "  :/:\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  not/RB\n",
      "  :/:\n",
      "  Before/IN\n",
      "  you/PRP\n",
      "  remove/VBP\n",
      "  scrub/NNS\n",
      "  or/CC\n",
      "  trees/NNS\n",
      "  ,/,\n",
      "  you/PRP\n",
      "  must/MD\n",
      "  get/VB\n",
      "  any/DT\n",
      "  relevant/JJ\n",
      "  consents/NNS\n",
      "  ,/,\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  :/:\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  do/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  from/IN\n",
      "  its/PRP$\n",
      "  start/NN\n",
      "  date/NN\n",
      "  ,/,\n",
      "  throughout/IN\n",
      "  each/DT\n",
      "  year/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  5-year/JJ\n",
      "  duration/NN\n",
      "  ./.\n",
      "  It/PRP\n",
      "  ’/VBD\n",
      "  s/VB\n",
      "  up/RP\n",
      "  to/TO\n",
      "  you/PRP\n",
      "  how/WRB\n",
      "  you/PRP\n",
      "  do/VBP\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ,/,\n",
      "  as/RB\n",
      "  long/RB\n",
      "  as/IN\n",
      "  you/PRP\n",
      "  :/:\n",
      "  Advice/NN\n",
      "  to/TO\n",
      "  help/VB\n",
      "  you/PRP\n",
      "  do/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  will/MD\n",
      "  be/VB\n",
      "  published/VBN\n",
      "  before/IN\n",
      "  applications/NNS\n",
      "  are/VBP\n",
      "  fully/RB\n",
      "  launched/VBN\n",
      "  from/IN\n",
      "  summer/NN\n",
      "  2024/CD\n",
      "  ./.\n",
      "  It/PRP\n",
      "  will/MD\n",
      "  not/RB\n",
      "  be/VB\n",
      "  part/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  requirements/NNS\n",
      "  ./.\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  keep/VB\n",
      "  evidence/NN\n",
      "  to/TO\n",
      "  show/VB\n",
      "  what/WP\n",
      "  you/PRP\n",
      "  ’/VBP\n",
      "  ve/JJ\n",
      "  done/VBN\n",
      "  to/TO\n",
      "  complete/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ,/,\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  :/:\n",
      "  If/IN\n",
      "  it/PRP\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  not/RB\n",
      "  clear/JJ\n",
      "  that/IN\n",
      "  you/PRP\n",
      "  ’/VBP\n",
      "  ve/JJ\n",
      "  done/VBN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  way/NN\n",
      "  that/WDT\n",
      "  could/MD\n",
      "  reasonably/RB\n",
      "  be/VB\n",
      "  expected/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  its/PRP$\n",
      "  aim/NN\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  may/MD\n",
      "  ask/VB\n",
      "  for/IN\n",
      "  this/DT\n",
      "  evidence/NN\n",
      "  ./.\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  supply/VB\n",
      "  the/DT\n",
      "  evidence/NN\n",
      "  if/IN\n",
      "  we/PRP\n",
      "  ask/VBP\n",
      "  for/IN\n",
      "  it/PRP\n",
      "  ./.\n",
      "  You/PRP\n",
      "  can/MD\n",
      "  do/VB\n",
      "  the/DT\n",
      "  following/JJ\n",
      "  actions/NNS\n",
      "  or/CC\n",
      "  options/NNS\n",
      "  on/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  area/NN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  land/NN\n",
      "  parcel/NN\n",
      "  as/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ./.\n",
      "  Some/DT\n",
      "  actions/NNS\n",
      "  or/CC\n",
      "  options/NNS\n",
      "  can/MD\n",
      "  only/RB\n",
      "  be/VB\n",
      "  done/VBN\n",
      "  on/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  area/NN\n",
      "  if/IN\n",
      "  they/PRP\n",
      "  ’/VBP\n",
      "  re/VB\n",
      "  done/VBN\n",
      "  at/IN\n",
      "  a/DT\n",
      "  different/JJ\n",
      "  time/NN\n",
      "  of/IN\n",
      "  year/NN\n",
      "  to/TO\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ./.\n",
      "  For/IN\n",
      "  example/NN\n",
      "  ,/,\n",
      "  winter/NN\n",
      "  cover/NN\n",
      "  followed/VBN\n",
      "  by/IN\n",
      "  a/DT\n",
      "  summer/NN\n",
      "  companion/NN\n",
      "  crop/NN\n",
      "  ./.\n",
      "  Read/VB\n",
      "  ‘/JJ\n",
      "  What/WP\n",
      "  to/TO\n",
      "  do/VB\n",
      "  ’/NNS\n",
      "  and/CC\n",
      "  ‘/NN\n",
      "  When/WRB\n",
      "  to/TO\n",
      "  do/VB\n",
      "  it/PRP\n",
      "  ’/VB\n",
      "  to/TO\n",
      "  find/VB\n",
      "  out/RP\n",
      "  when/WRB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  must/MD\n",
      "  be/VB\n",
      "  done/VBN\n",
      "  ./.\n",
      "  If/IN\n",
      "  an/DT\n",
      "  action/NN\n",
      "  or/CC\n",
      "  option/NN\n",
      "  can/MD\n",
      "  not/RB\n",
      "  be/VB\n",
      "  located/VBN\n",
      "  on/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  area/NN\n",
      "  ,/,\n",
      "  you/PRP\n",
      "  may/MD\n",
      "  be/VB\n",
      "  able/JJ\n",
      "  to/TO\n",
      "  do/VB\n",
      "  it/PRP\n",
      "  on/IN\n",
      "  a/DT\n",
      "  different/JJ\n",
      "  area/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  land/NN\n",
      "  parcel/NN\n",
      "  ./.\n",
      "  Read/NNP\n",
      "  section/NN\n",
      "  6/CD\n",
      "  ‘/NN\n",
      "  Eligible/JJ\n",
      "  land/NN\n",
      "  in/IN\n",
      "  other/JJ\n",
      "  funding/NN\n",
      "  schemes/NNS\n",
      "  ’/VBP\n",
      "  for/IN\n",
      "  more/JJR\n",
      "  information/NN\n",
      "  ./.\n",
      "  You/PRP\n",
      "  can/MD\n",
      "  do/VB\n",
      "  the/DT\n",
      "  following/JJ\n",
      "  actions/NNS\n",
      "  or/CC\n",
      "  options/NNS\n",
      "  on/IN\n",
      "  the/DT\n",
      "  eligible/JJ\n",
      "  boundaries/NNS\n",
      "  of/IN\n",
      "  a/DT\n",
      "  land/NN\n",
      "  parcel/NN\n",
      "  entered/VBD\n",
      "  into/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  :/:\n",
      "  (PERSON Don/NNP)\n",
      "  ’/NNP\n",
      "  t/NN\n",
      "  include/VBP\n",
      "  personal/JJ\n",
      "  or/CC\n",
      "  financial/JJ\n",
      "  information/NN\n",
      "  like/IN\n",
      "  your/PRP$\n",
      "  (ORGANIZATION National/NNP Insurance/NNP)\n",
      "  number/NN\n",
      "  or/CC\n",
      "  credit/NN\n",
      "  card/NN\n",
      "  details/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "nltk.download('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  This/DT\n",
      "  is/VBZ\n",
      "  an/DT\n",
      "  action/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Sustainable/JJ Farming/NNP Incentive/NNP)\n",
      "  (/(\n",
      "  (ORGANIZATION SFI/NNP)\n",
      "  )/)\n",
      "  scheme/NN\n",
      "  :/:\n",
      "  expanded/VBN\n",
      "  offer/NN\n",
      "  for/IN\n",
      "  2024/CD\n",
      "  ./.\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  read/VB\n",
      "  the/DT\n",
      "  (ORGANIZATION SFI/NNP)\n",
      "  scheme/NN\n",
      "  information/NN\n",
      "  to/TO\n",
      "  understand/VB\n",
      "  the/DT\n",
      "  scheme/NN\n",
      "  rules/NNS\n",
      "  and/CC\n",
      "  how/WRB\n",
      "  to/TO\n",
      "  apply/VB\n",
      "  ./.\n",
      "  5/CD\n",
      "  years/NNS\n",
      "  £215/JJ\n",
      "  per/IN\n",
      "  hectare/NN\n",
      "  (/(\n",
      "  ha/NN\n",
      "  )/)\n",
      "  per/IN\n",
      "  year/NN\n",
      "  This/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  aim/NN\n",
      "  is/VBZ\n",
      "  that/IN\n",
      "  there/EX\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  a/DT\n",
      "  well-managed/JJ\n",
      "  ,/,\n",
      "  intact/JJ\n",
      "  grass/NN\n",
      "  sward/NN\n",
      "  growing/VBG\n",
      "  over/IN\n",
      "  the/DT\n",
      "  historic/JJ\n",
      "  or/CC\n",
      "  archaeological/JJ\n",
      "  feature/NN\n",
      "  throughout/IN\n",
      "  the/DT\n",
      "  year/NN\n",
      "  ,/,\n",
      "  with/IN\n",
      "  minimal/JJ\n",
      "  scrub/NN\n",
      "  cover/NN\n",
      "  and/CC\n",
      "  bare/JJ\n",
      "  ground/NN\n",
      "  ./.\n",
      "  The/DT\n",
      "  purpose/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  is/VBZ\n",
      "  to/TO\n",
      "  :/:\n",
      "  You/PRP\n",
      "  can/MD\n",
      "  do/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  on/IN\n",
      "  land/NN\n",
      "  located/VBN\n",
      "  above/IN\n",
      "  and/CC\n",
      "  below/IN\n",
      "  the/DT\n",
      "  moorland/NN\n",
      "  line/NN\n",
      "  that/IN\n",
      "  ’/JJ\n",
      "  s/NN\n",
      "  :/:\n",
      "  Total/NN\n",
      "  or/CC\n",
      "  part/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  available/JJ\n",
      "  area/NN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  land/NN\n",
      "  parcel/NN\n",
      "  ./.\n",
      "  This/DT\n",
      "  action/NN\n",
      "  is/VBZ\n",
      "  static/JJ\n",
      "  ./.\n",
      "  This/DT\n",
      "  means/VBZ\n",
      "  you/PRP\n",
      "  must/MD\n",
      "  do/VB\n",
      "  it/PRP\n",
      "  at/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  location/NN\n",
      "  each/DT\n",
      "  year/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  duration/NN\n",
      "  ./.\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  manage/VB\n",
      "  the/DT\n",
      "  area/NN\n",
      "  containing/VBG\n",
      "  the/DT\n",
      "  historic/NN\n",
      "  or/CC\n",
      "  archaeological/JJ\n",
      "  feature/NN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  way/NN\n",
      "  that/WDT\n",
      "  can/MD\n",
      "  reasonably/RB\n",
      "  be/VB\n",
      "  expected/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  aim/NN\n",
      "  ./.\n",
      "  This/DT\n",
      "  includes/VBZ\n",
      "  :/:\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  not/RB\n",
      "  :/:\n",
      "  Before/IN\n",
      "  you/PRP\n",
      "  remove/VBP\n",
      "  scrub/NNS\n",
      "  or/CC\n",
      "  trees/NNS\n",
      "  ,/,\n",
      "  you/PRP\n",
      "  must/MD\n",
      "  get/VB\n",
      "  any/DT\n",
      "  relevant/JJ\n",
      "  consents/NNS\n",
      "  ,/,\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  :/:\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  do/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  from/IN\n",
      "  its/PRP$\n",
      "  start/NN\n",
      "  date/NN\n",
      "  ,/,\n",
      "  throughout/IN\n",
      "  each/DT\n",
      "  year/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  5-year/JJ\n",
      "  duration/NN\n",
      "  ./.\n",
      "  It/PRP\n",
      "  ’/VBD\n",
      "  s/VB\n",
      "  up/RP\n",
      "  to/TO\n",
      "  you/PRP\n",
      "  how/WRB\n",
      "  you/PRP\n",
      "  do/VBP\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ,/,\n",
      "  as/RB\n",
      "  long/RB\n",
      "  as/IN\n",
      "  you/PRP\n",
      "  :/:\n",
      "  Advice/NN\n",
      "  to/TO\n",
      "  help/VB\n",
      "  you/PRP\n",
      "  do/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  will/MD\n",
      "  be/VB\n",
      "  published/VBN\n",
      "  before/IN\n",
      "  applications/NNS\n",
      "  are/VBP\n",
      "  fully/RB\n",
      "  launched/VBN\n",
      "  from/IN\n",
      "  summer/NN\n",
      "  2024/CD\n",
      "  ./.\n",
      "  It/PRP\n",
      "  will/MD\n",
      "  not/RB\n",
      "  be/VB\n",
      "  part/NN\n",
      "  of/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  requirements/NNS\n",
      "  ./.\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  keep/VB\n",
      "  evidence/NN\n",
      "  to/TO\n",
      "  show/VB\n",
      "  what/WP\n",
      "  you/PRP\n",
      "  ’/VBP\n",
      "  ve/JJ\n",
      "  done/VBN\n",
      "  to/TO\n",
      "  complete/VB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ,/,\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  :/:\n",
      "  If/IN\n",
      "  it/PRP\n",
      "  ’/VBZ\n",
      "  s/JJ\n",
      "  not/RB\n",
      "  clear/JJ\n",
      "  that/IN\n",
      "  you/PRP\n",
      "  ’/VBP\n",
      "  ve/JJ\n",
      "  done/VBN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  way/NN\n",
      "  that/WDT\n",
      "  could/MD\n",
      "  reasonably/RB\n",
      "  be/VB\n",
      "  expected/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  its/PRP$\n",
      "  aim/NN\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  may/MD\n",
      "  ask/VB\n",
      "  for/IN\n",
      "  this/DT\n",
      "  evidence/NN\n",
      "  ./.\n",
      "  You/PRP\n",
      "  must/MD\n",
      "  supply/VB\n",
      "  the/DT\n",
      "  evidence/NN\n",
      "  if/IN\n",
      "  we/PRP\n",
      "  ask/VBP\n",
      "  for/IN\n",
      "  it/PRP\n",
      "  ./.\n",
      "  You/PRP\n",
      "  can/MD\n",
      "  do/VB\n",
      "  the/DT\n",
      "  following/JJ\n",
      "  actions/NNS\n",
      "  or/CC\n",
      "  options/NNS\n",
      "  on/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  area/NN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  land/NN\n",
      "  parcel/NN\n",
      "  as/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ./.\n",
      "  Some/DT\n",
      "  actions/NNS\n",
      "  or/CC\n",
      "  options/NNS\n",
      "  can/MD\n",
      "  only/RB\n",
      "  be/VB\n",
      "  done/VBN\n",
      "  on/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  area/NN\n",
      "  if/IN\n",
      "  they/PRP\n",
      "  ’/VBP\n",
      "  re/VB\n",
      "  done/VBN\n",
      "  at/IN\n",
      "  a/DT\n",
      "  different/JJ\n",
      "  time/NN\n",
      "  of/IN\n",
      "  year/NN\n",
      "  to/TO\n",
      "  this/DT\n",
      "  action/NN\n",
      "  ./.\n",
      "  For/IN\n",
      "  example/NN\n",
      "  ,/,\n",
      "  winter/NN\n",
      "  cover/NN\n",
      "  followed/VBN\n",
      "  by/IN\n",
      "  a/DT\n",
      "  summer/NN\n",
      "  companion/NN\n",
      "  crop/NN\n",
      "  ./.\n",
      "  Read/VB\n",
      "  ‘/JJ\n",
      "  What/WP\n",
      "  to/TO\n",
      "  do/VB\n",
      "  ’/NNS\n",
      "  and/CC\n",
      "  ‘/NN\n",
      "  When/WRB\n",
      "  to/TO\n",
      "  do/VB\n",
      "  it/PRP\n",
      "  ’/VB\n",
      "  to/TO\n",
      "  find/VB\n",
      "  out/RP\n",
      "  when/WRB\n",
      "  this/DT\n",
      "  action/NN\n",
      "  must/MD\n",
      "  be/VB\n",
      "  done/VBN\n",
      "  ./.\n",
      "  If/IN\n",
      "  an/DT\n",
      "  action/NN\n",
      "  or/CC\n",
      "  option/NN\n",
      "  can/MD\n",
      "  not/RB\n",
      "  be/VB\n",
      "  located/VBN\n",
      "  on/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  area/NN\n",
      "  ,/,\n",
      "  you/PRP\n",
      "  may/MD\n",
      "  be/VB\n",
      "  able/JJ\n",
      "  to/TO\n",
      "  do/VB\n",
      "  it/PRP\n",
      "  on/IN\n",
      "  a/DT\n",
      "  different/JJ\n",
      "  area/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  land/NN\n",
      "  parcel/NN\n",
      "  ./.\n",
      "  Read/NNP\n",
      "  section/NN\n",
      "  6/CD\n",
      "  ‘/NN\n",
      "  Eligible/JJ\n",
      "  land/NN\n",
      "  in/IN\n",
      "  other/JJ\n",
      "  funding/NN\n",
      "  schemes/NNS\n",
      "  ’/VBP\n",
      "  for/IN\n",
      "  more/JJR\n",
      "  information/NN\n",
      "  ./.\n",
      "  You/PRP\n",
      "  can/MD\n",
      "  do/VB\n",
      "  the/DT\n",
      "  following/JJ\n",
      "  actions/NNS\n",
      "  or/CC\n",
      "  options/NNS\n",
      "  on/IN\n",
      "  the/DT\n",
      "  eligible/JJ\n",
      "  boundaries/NNS\n",
      "  of/IN\n",
      "  a/DT\n",
      "  land/NN\n",
      "  parcel/NN\n",
      "  entered/VBD\n",
      "  into/IN\n",
      "  this/DT\n",
      "  action/NN\n",
      "  :/:\n",
      "  (PERSON Don/NNP)\n",
      "  ’/NNP\n",
      "  t/NN\n",
      "  include/VBP\n",
      "  personal/JJ\n",
      "  or/CC\n",
      "  financial/JJ\n",
      "  information/NN\n",
      "  like/IN\n",
      "  your/PRP$\n",
      "  (ORGANIZATION National/NNP Insurance/NNP)\n",
      "  number/NN\n",
      "  or/CC\n",
      "  credit/NN\n",
      "  card/NN\n",
      "  details/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sentence = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "tokens = word_tokenize(text)\n",
    "tags = pos_tag(tokens)\n",
    "entities = ne_chunk(tags)\n",
    "\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
